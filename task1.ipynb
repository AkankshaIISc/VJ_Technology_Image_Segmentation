{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85d7cf1",
   "metadata": {},
   "source": [
    "### Load the COCO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/zips/train2017.zip # Example COCO download\n",
    "!unzip train2017.zip # Unzip the downloaded file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3df05",
   "metadata": {},
   "source": [
    "### To find the number of images in the train2017 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76a6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_image_dir = '/content/train2017'  # Replace with your actual directory path\n",
    "\n",
    "if os.path.exists(train_image_dir):\n",
    "    image_files = [f for f in os.listdir(train_image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))] # only count image files\n",
    "    num_images = len(image_files)\n",
    "    print(f\"Number of images in train2017: {num_images}\")\n",
    "else:\n",
    "    print(f\"Directory '{train_image_dir}' does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b94d1d1",
   "metadata": {},
   "source": [
    "### Download annotation file for trainval2017 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde78551",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad98c2",
   "metadata": {},
   "source": [
    "### To see number of items in annotations file (instances_train2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "annotation_file = '/content/annotations/annotations/instances_train2017.json'\n",
    "\n",
    "try:\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    num_images = len(data['images'])\n",
    "    num_annotations = len(data['annotations'])\n",
    "\n",
    "    print(f\"Number of images in instances_train2017.json: {num_images}\")\n",
    "    print(f\"Number of annotations in instances_train2017.json: {num_annotations}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{annotation_file}' not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: File '{annotation_file}' is not a valid JSON file.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Key '{e}' not found in the JSON file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed153e",
   "metadata": {},
   "source": [
    "### Load a few elements from the instances_train2017 file to see the structure in which data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8bd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "annotation_file = '/content/annotations/annotations/instances_train2017.json'\n",
    "\n",
    "try:\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Print the first few image entries\n",
    "    print(\"First few image entries:\")\n",
    "    for image in data['images'][10:20]:  # Print the first 5 image entries\n",
    "        print(image)\n",
    "\n",
    "    print(\"\\nFirst few annotation entries:\")\n",
    "    for annotation in data['annotations'][10:20]: # print the first 5 annotation entries\n",
    "        print(annotation)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{annotation_file}' not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: File '{annotation_file}' is not a valid JSON file.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Key '{e}' not found in the JSON file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5ba5e",
   "metadata": {},
   "source": [
    "## create subset of 8k images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "train_image_dir = '/content/train2017'\n",
    "train_subset_dir = '/content/train_subset'\n",
    "annotation_file = '/content/annotations/annotations/instances_train2017.json'\n",
    "num_images_to_select = 8000\n",
    "\n",
    "# Create the subset directory\n",
    "os.makedirs(train_subset_dir, exist_ok=True)\n",
    "\n",
    "# Get a list of image files\n",
    "image_files = [f for f in os.listdir(train_image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Randomly select 8000 images\n",
    "selected_images = random.sample(image_files, min(num_images_to_select, len(image_files)))\n",
    "\n",
    "# Set the random seed\n",
    "random_seed = 42 \n",
    "random.seed(random_seed)\n",
    "\n",
    "# Copy the selected images to the subset directory\n",
    "for image_file in selected_images:\n",
    "    src_path = os.path.join(train_image_dir, image_file)\n",
    "    dst_path = os.path.join(train_subset_dir, image_file)\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "print(f\"Copied {len(selected_images)} images to {train_subset_dir}\")\n",
    "\n",
    "# Process the annotation file.\n",
    "with open(annotation_file, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "image_id_to_filename = {img['id']: img['file_name'] for img in annotations['images']}\n",
    "filename_to_image_id = {v: k for k, v in image_id_to_filename.items()}\n",
    "\n",
    "subset_image_ids = [filename_to_image_id[f] for f in selected_images]\n",
    "\n",
    "# Filter the annotations.\n",
    "subset_images = [img for img in annotations['images'] if img['id'] in subset_image_ids]\n",
    "subset_annotations = [ann for ann in annotations['annotations'] if ann['image_id'] in subset_image_ids]\n",
    "\n",
    "# Create a new annotation file.\n",
    "subset_annotation_data = {'images': subset_images, 'annotations': subset_annotations}\n",
    "\n",
    "with open('/content/subset_train_annotations.json', 'w') as f:\n",
    "    json.dump(subset_annotation_data, f)\n",
    "\n",
    "print(\"Created subset train annotation file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4035ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r train_subset.zip /content/train_subset #to zip the subset directory\n",
    "!zip -r subset_train_annotations.zip /content/subset_train_annotations.json #to zip the annotation file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413fe13d",
   "metadata": {},
   "source": [
    "#### to see what does each category_id correspond to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bf17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "annotation_file = '/content/annotations/annotations/instances_train2017.json'  # Replace with your actual path\n",
    "\n",
    "try:\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    categories = data.get('categories', [])\n",
    "\n",
    "    if not categories:\n",
    "        print(\"No category information found in the annotation file.\")\n",
    "    else:\n",
    "        print(\"Category Mapping:\")\n",
    "        for category in categories:\n",
    "            print(f\"  ID: {category['id']}, Name: {category['name']}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{annotation_file}' not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: File '{annotation_file}' is not a valid JSON file.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Key '{e}' not found in the JSON file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ce6f3",
   "metadata": {},
   "source": [
    "#### ## Creating mask: storing category_id along with image name to clearly see which category_id it consists of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_segmentation_masks(image_dir, annotation_file, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "\n",
    "    image_annotations = {}\n",
    "    for ann in annotations['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        if image_id not in image_annotations:\n",
    "            image_annotations[image_id] = []\n",
    "        image_annotations[image_id].append(ann)\n",
    "\n",
    "    image_id_to_filename = {img['id']: img['file_name'] for img in annotations['images']}\n",
    "\n",
    "    for image_id, anns in tqdm(image_annotations.items(), desc=\"Processing Images\"):\n",
    "        filename = image_id_to_filename[image_id]\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            width, height = image.size\n",
    "\n",
    "            mask = np.zeros((height, width), dtype=np.uint8)\n",
    "            mask_image = Image.new('L', (width, height), 0)\n",
    "            draw = ImageDraw.Draw(mask_image)\n",
    "\n",
    "            present_category_ids = sorted(list(set()))  # Sorted list for consistent naming\n",
    "\n",
    "            for ann in anns:\n",
    "                segmentation = ann['segmentation']\n",
    "                category_id = ann['category_id']\n",
    "                present_category_ids.append(category_id)  # Add category_id to the list\n",
    "\n",
    "                if isinstance(segmentation, list):  # Polygon segmentation\n",
    "                    for polygon in segmentation:\n",
    "                        polygon_points = [(polygon[i], polygon[i + 1]) for i in range(0, len(polygon), 2)]\n",
    "                        draw.polygon(polygon_points, fill=int(category_id * 100))\n",
    "                        mask = np.maximum(mask, np.array(mask_image))\n",
    "                        mask_image = Image.new('L', (width, height), 0)\n",
    "\n",
    "            mask_image = Image.fromarray(mask)\n",
    "\n",
    "            # Create the category ID string for the filename\n",
    "            category_id_str = '_'.join(map(str, sorted(list(set(present_category_ids)))))  # Unique sorted IDs\n",
    "\n",
    "            mask_filename = f\"{os.path.splitext(filename)[0]}_mask_cats_{category_id_str}.png\"\n",
    "            mask_path = os.path.join(output_dir, mask_filename)\n",
    "            mask_image.save(mask_path)\n",
    "\n",
    "            print(f\"Mask saved to {mask_path}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Image not found: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "# Example usage (replace with your actual paths):\n",
    "image_dir = '/content/train_subset'\n",
    "annotation_file = '/content/subset_train_annotations.json'\n",
    "output_dir = '/content/masks_2'\n",
    "\n",
    "create_segmentation_masks(image_dir, annotation_file, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b939dfe",
   "metadata": {},
   "source": [
    "### ## Visualizing specific images from train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "image_dir = '/content/train_subset'  # Replace with the actual path to your train_subset directory\n",
    "image_filename = '000000000643.jpg'  # Replace with the actual filename of the image you want to see\n",
    "\n",
    "image_path = os.path.join(image_dir, image_filename)\n",
    "\n",
    "try:\n",
    "    image = Image.open(image_path)\n",
    "    plt.imshow(image)\n",
    "    plt.title(image_filename)\n",
    "    plt.show()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Image file '{image_path}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r masks_2.zip /content/masks_2 #to zip the masks directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
